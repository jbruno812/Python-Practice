{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: The Competition\n",
    "We'll be learning how to generate a submission for a Kaggle competition. Kaggle is a site where you create algorithms, and compete against machine learning practitioners around the world. Your algorithm wins if it's the most accurate on a given dataset. Kaggle is a fun way to practice your machine learning skills.\n",
    "\n",
    "Kaggle has several different competitions on their site. One of them is about predicting which passengers survived the sinking of the Titanic. In this notebook, we'll explore the data, train our first model, and prepare our first submission to the competition.\n",
    "\n",
    "Let's take a look at the dataset. Each row represents a passenger on the Titanic, and some information about them. \n",
    "\n",
    "- PassengerId -- A numerical id assigned to each passenger.\n",
    "- Survived -- Whether the passenger survived (1), or didn't (0). We'll be making predictions for this column.\n",
    "- Pclass -- The class the passenger was in -- first class (1), second class (2), or third class (3).\n",
    "- Name -- the name of the passenger.\n",
    "- Sex -- The gender of the passenger -- male or female.\n",
    "- Age -- The age of the passenger. Fractional.\n",
    "- SibSp -- The number of siblings and spouses the passenger had on board.\n",
    "- Parch -- The number of parents and children the passenger had on board.\n",
    "- Ticket -- The ticket number of the passenger.\n",
    "- Fare -- How much the passenger paid for the ticker.\n",
    "- Cabin -- Which cabin the passenger was in.\n",
    "- Embarked -- Where the passenger boarded the Titanic.\n",
    "\n",
    "A good first step is to think logically about the columns and what we're trying to predict. What variables might logically affect the outcome of survived?\n",
    "\n",
    "We know that women and children were more likely to survive. Thus, Age and Sex are probably good predictors. It's also logical to think that passenger class might affect the outcome, as first class cabins were closer to the deck of the ship. Fare is tied to passenger class, and will probably be highly correlated with it, but might add some additional information. Number of siblings and parents/children will probably be correlated with survival one way or the other, as either there are more people to help you, or more people to think about and try to save.\n",
    "\n",
    "There's a less clear link between survival and columns like Embarked (maybe there is some information about how close to the top of the ship people's cabins were here), Ticket, and Name.\n",
    "\n",
    "This step is generally known as acquiring domain knowledge, and it fairly important to most machine learning tasks. We're looking to engineer the features so that we maximize the information we have about what we're trying to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Looking At The Data\n",
    "We'll be using the pandas library, and scikit-learn to analyze our data and create a submission. \n",
    "A good second step is to look at high level descriptors of the data. In this case, we can use the pandas .describe() method to look at different characteristics of each numeric column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    PassengerId  Survived  Pclass  \\\n",
      "1             2         1       1   \n",
      "3             4         1       1   \n",
      "6             7         0       1   \n",
      "10           11         1       3   \n",
      "11           12         1       1   \n",
      "\n",
      "                                                 Name     Sex   Age  SibSp  \\\n",
      "1   Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "3        Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "6                             McCarthy, Mr. Timothy J    male  54.0      0   \n",
      "10                    Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
      "11                           Bonnell, Miss. Elizabeth  female  58.0      0   \n",
      "\n",
      "    Parch    Ticket     Fare Cabin Embarked  \n",
      "1       0  PC 17599  71.2833   C85        C  \n",
      "3       0    113803  53.1000  C123        S  \n",
      "6       0     17463  51.8625   E46        S  \n",
      "10      1   PP 9549  16.7000    G6        S  \n",
      "11      0    113783  26.5500  C103        S  \n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   183.000000  183.000000  183.000000  183.000000  183.000000   \n",
      "mean    455.366120    0.672131    1.191257   35.674426    0.464481   \n",
      "std     247.052476    0.470725    0.515187   15.643866    0.644159   \n",
      "min       2.000000    0.000000    1.000000    0.920000    0.000000   \n",
      "25%     263.500000    0.000000    1.000000   24.000000    0.000000   \n",
      "50%     457.000000    1.000000    1.000000   36.000000    0.000000   \n",
      "75%     676.000000    1.000000    1.000000   47.500000    1.000000   \n",
      "max     890.000000    1.000000    3.000000   80.000000    3.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  183.000000  183.000000  \n",
      "mean     0.475410   78.682469  \n",
      "std      0.754617   76.347843  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000   29.700000  \n",
      "50%      0.000000   57.000000  \n",
      "75%      1.000000   90.000000  \n",
      "max      4.000000  512.329200  \n"
     ]
    }
   ],
   "source": [
    "# import your dataset\n",
    "# We can use the pandas library in python to read in the csv file.\n",
    "# This creates a pandas dataframe and assigns it to the titanic variable.\n",
    "titanic = pd.read_csv('Data/titanic_train.csv').dropna()\n",
    "\n",
    "# Print the first 5 rows of the dataframe.\n",
    "print(titanic.head(5))\n",
    "\n",
    "# describe the dataset\n",
    "print(titanic.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Missing Data\n",
    "When you used .describe() on the titanic dataframe in the last screen, you might have noticed that the Age column has a count of 714 when all the other columns have a count of 891. This indicates that there are missing values in the Age column -- the count is of non-missing (null, NA, or not a number) values.\n",
    "\n",
    "This means that the data isn't perfectly clean, and we're going to have to clean it ourselves. We don't want to have to remove the rows with missing values, because more data helps us train a better algorithm. We also don't want to get rid of the whole column, as age is probably fairly important to our analysis.\n",
    "\n",
    "There are many strategies for cleaning up missing data, but a simple one is to just fill in all the missing values with the median of all the values in the column.\n",
    "\n",
    "We can select a single column by indexing the dataframe like a dictionary. This gives us a pandas series:\n",
    "\n",
    "\n",
    "titanic[\"Age\"]\n",
    "We can then use the .fillna method on the series to replace any missing values. .fillna takes one argument, the value to replace the missing values with.\n",
    "\n",
    "In our case, we want to fill with the median of the column:\n",
    "\n",
    "\n",
    ".fillna(titanic[\"Age\"].median())\n",
    "We then have to assign the result back to the column to replace it:\n",
    "\n",
    "\n",
    "titanic[\"Age\"] = titanic[\"Age\"].fillna(titanic[\"Age\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"Age\"] = titanic[\"Age\"].fillna(titanic[\"Age\"].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4: Non-Numeric Columns\n",
    "When we used .describe(), you might have also noticed that not all the columns were shown. Only the numeric columns were shown. Several of our columns are non-numeric, which is a problem when it comes time to make predictions -- we can't feed non-numeric columns into a machine learning algorithm and expect it to make sense of them.\n",
    "\n",
    "We have to either exclude our non-numeric columns when we train our algorithm (Name, Sex, Cabin, Embarked, and Ticket), or find a way to convert them to numeric columns.\n",
    "\n",
    "We'll ignore the Ticket, Cabin, and Name columns. There isn't much information we can extract from there. Most of the values in the cabin column are missing (only 204 values out of 891 rows), and it likely isn't a particularly informative column in the first place. The Ticket and Name columns are unlikely to tell us much without some domain knowledge about what the ticket numbers mean, and about which names correlate with characteristics like large or rich families."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5: Converting The Sex Column\n",
    "The Sex column is non-numeric, but we want to keep it around -- it could be very informative. We can convert it to a numeric column by replacing each gender with a numeric code. A machine learning algorithm will then be able to use these categories to make predictions.\n",
    "\n",
    "To do this, we first have to find all the unique genders in the column (we know male and female are there, but did whoever recorded the dataset use another code for missing values?). We'll also assign a code of 0 to male, and a code of 1 to female.\n",
    "\n",
    "We can select all the male values in the Sex column with:\n",
    "\n",
    "\n",
    "titanic.loc[titanic[\"Sex\"] == \"male\", \"Sex\"]\n",
    "\n",
    "We can then replace all these values with 0:\n",
    "\n",
    "\n",
    "titanic.loc[titanic[\"Sex\"] == \"male\", \"Sex\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['female' 'male']\n"
     ]
    }
   ],
   "source": [
    "# Find all the unique genders -- the column appears to contain only male and female.\n",
    "print(titanic[\"Sex\"].unique())\n",
    "\n",
    "# Replace all the occurences of male with the number 0.\n",
    "titanic.loc[titanic[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "titanic.loc[titanic[\"Sex\"] == \"female\", \"Sex\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6: Converting The Embarked Column\n",
    "We now can convert the Embarked column to codes the same way we converted the Sex column. The unique values in Embarked are S, C, Q, and missing (nan). Each letter is an abbreviation of an embarkation port name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C' 'S' 'Q']\n"
     ]
    }
   ],
   "source": [
    "# Find all the unique values for \"Embarked\".\n",
    "print(titanic[\"Embarked\"].unique())\n",
    "titanic[\"Embarked\"] = titanic[\"Embarked\"].fillna(\"S\")\n",
    "\n",
    "titanic.loc[titanic[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "titanic.loc[titanic[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "titanic.loc[titanic[\"Embarked\"] == \"Q\", \"Embarked\"] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7: Cross Validation\n",
    "Below, we will use cross validation approach to build up and select models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the X and y variables\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "predictors = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Embarked']\n",
    "\n",
    "X = titanic[predictors]\n",
    "y = titanic[\"Survived\"]\n",
    "\n",
    "# Instruction: change the value of random_state\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.6, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on test set: 0.73\n"
     ]
    }
   ],
   "source": [
    "# Instruction: fit the model using X_train and y_train\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth=6)\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "print('Accuracy of Decision Tree classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pclass', 0.03508613196339947), ('Sex', 0.37486751476415575), ('Age', 0.5809902919463712), ('SibSp', 0.0), ('Parch', 0.009056061326073698), ('Embarked', 0.0)]\n"
     ]
    }
   ],
   "source": [
    "# View a list of the features and their importance scores\n",
    "print(list(zip(titanic[predictors], clf.feature_importances_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a random forest model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8: Processing The Test Set\n",
    "Our accuracy is decent, but not great. You may try a few things to make it better.\n",
    "\n",
    "Now, we need to make a submission to the competition. To do this, we need to take the exact same steps on the test data that we took on the training data. If we don't do the exact same operations, then we won't be able to make valid predictions on it.\n",
    "\n",
    "These operations are all the changes we made to the columns before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_test = pd.read_csv(\"Data/titanic_test.csv\")\n",
    "titanic_test[\"Age\"] = titanic_test[\"Age\"].fillna(titanic[\"Age\"].median())\n",
    "titanic_test[\"Fare\"] = titanic_test[\"Fare\"].fillna(titanic_test[\"Fare\"].median())\n",
    "titanic_test.loc[titanic_test[\"Sex\"] == \"male\", \"Sex\"] = 0 \n",
    "titanic_test.loc[titanic_test[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "titanic_test[\"Embarked\"] = titanic_test[\"Embarked\"].fillna(\"S\")\n",
    "\n",
    "titanic_test.loc[titanic_test[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "titanic_test.loc[titanic_test[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "titanic_test.loc[titanic_test[\"Embarked\"] == \"Q\", \"Embarked\"] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.Generating A Submission File\n",
    "Now we have everything we need to generate a submission for the competition!\n",
    "\n",
    "First, we have to train an algorithm on the training data. Then, we make predictions on the test set. Finally, we'll generate a csv file with the predictions and passenger ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the test set.\n",
    "predictions = clf.predict(titanic_test[predictors])\n",
    "\n",
    "# Create a new dataframe with only the columns Kaggle wants from the dataset.\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": titanic_test[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "    })\n",
    "\n",
    "submission.to_csv(\"Data/kaggle.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
